import os
import sys
from dotenv import load_dotenv
from langchain_community.document_loaders import Docx2txtLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain_chroma import Chroma
import google.generativeai as genai

# 1. –ù–∞—Å—Ç—Ä–æ–π–∫–∞
load_dotenv()
api_key = os.getenv("GOOGLE_API_KEY")

SOURCE_FILE = "training_data/all_transcripts.docx" 
CHROMA_PATH = "chroma_db"

if not api_key:
    raise ValueError("‚ùå –û—à–∏–±–∫–∞: –ù–µ –Ω–∞–π–¥–µ–Ω GOOGLE_API_KEY –≤ —Ñ–∞–π–ª–µ .env")

def get_available_embedding_model():
    """–§—É–Ω–∫—Ü–∏—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏—â–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—É—é –º–æ–¥–µ–ª—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞"""
    print("üîç –ò—â–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –≤ –≤–∞—à–µ–º –∞–∫–∫–∞—É–Ω—Ç–µ Google...")
    try:
        genai.configure(api_key=api_key)
        for model in genai.list_models():
            if 'embedContent' in model.supported_generation_methods:
                print(f"   ‚úÖ –ù–∞–π–¥–µ–Ω–∞ –º–æ–¥–µ–ª—å: {model.name}")
                return model.name
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –º–æ–¥–µ–ª–µ–π: {e}")
        # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏, –ø—Ä–æ–±—É–µ–º —Å–∞–º—É—é –ø–æ–ø—É–ª—è—Ä–Ω—É—é –Ω–∞—É–≥–∞–¥
        return "models/embedding-001"
    
    return None

def ingest_one_big_file():
    # 2. –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏
    model_name = get_available_embedding_model()
    if not model_name:
        print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏ –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞! –ü—Ä–æ–≤–µ—Ä—å—Ç–µ API –∫–ª—é—á.")
        return

    print(f"üöÄ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É —Ñ–∞–π–ª–∞: {SOURCE_FILE} —Å –º–æ–¥–µ–ª—å—é {model_name}")

    if not os.path.exists(SOURCE_FILE):
        print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω! –ü–æ–ª–æ–∂–∏—Ç–µ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç—ã –≤ {SOURCE_FILE}")
        return

    # 3. –ó–∞–≥—Ä—É–∑–∫–∞
    try:
        loader = Docx2txtLoader(SOURCE_FILE)
        document = loader.load()
        if not document:
             print("‚ùå –§–∞–π–ª –ø—É—Å—Ç.")
             return
        print(f"üìÑ –§–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω. –î–ª–∏–Ω–∞: {len(document[0].page_content)} —Å–∏–º–≤–æ–ª–æ–≤")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {e}")
        return

    # 4. –ù–∞—Ä–µ–∑–∫–∞
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=2000,
        chunk_overlap=500,
        separators=["\n\n", "\n", ". ", " ", ""]
    )
    chunks = text_splitter.split_documents(document)
    print(f"‚úÇÔ∏è –§–∞–π–ª –Ω–∞—Ä–µ–∑–∞–Ω –Ω–∞ {len(chunks)} —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤.")

    # 5. –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    print("üß† –°–æ–∑–¥–∞–µ–º –±–∞–∑—É –∑–Ω–∞–Ω–∏–π...")
    try:
        embeddings = GoogleGenerativeAIEmbeddings(model=model_name)
        Chroma.from_documents(
            documents=chunks, 
            embedding=embeddings,
            persist_directory=CHROMA_PATH
        )
        print(f"üéâ –£–°–ü–ï–•! –°—Ç–∏–ª—å –î–∂–æ–Ω–Ω–∏ –•–∞—Ä—Ä–∏—Å–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ –ø–∞–ø–∫—É '{CHROMA_PATH}'")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –±–∞–∑—ã: {e}")

if __name__ == "__main__":
    ingest_one_big_file()